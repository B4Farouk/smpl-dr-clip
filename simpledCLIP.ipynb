{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub3yRD8U9UVO"
      },
      "source": [
        "### Import the GitHub Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q4bLvJx_HNw",
        "outputId": "7065afbd-4d5c-450a-adad-226981b03b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 286 (delta 71), reused 53 (delta 21), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (286/286), 38.66 MiB | 20.21 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf project #remove if it already exists \n",
        "!git clone https://github.com/B4Farouk/smpl-dr-clip project\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGLZOp-aG4l_"
      },
      "source": [
        "### Install Dependencies\n",
        "---\n",
        "- pytorch (1.12.1)\n",
        "- torchvision (0.13.1)\n",
        "---\n",
        "- pytorch3d\n",
        "---\n",
        "- SMPL\n",
        "- chumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EGDGdk6i-gsr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPKeYdaC-ft5",
        "outputId": "272e81b4-10a6-4144-df01-9fb59815d92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.1) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "# install torch\n",
        "try:\n",
        "    import torch\n",
        "    if torch.__version__ != \"1.12.1\":\n",
        "      raise ModuleNotFoundError()\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch==1.12.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L48uBYSS-iq4",
        "outputId": "371225c7-0d1e-4e2e-856b-81e9dd91a6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision==0.13.1 in /usr/local/lib/python3.8/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# install torchvision\n",
        "try:\n",
        "    import torchvision\n",
        "    if torchvision.__version__ != \"0.13.1\":\n",
        "      raise ModuleNotFoundError()\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torchvision==0.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBC26H1Z-k2A",
        "outputId": "42f2c9d9-71b7-4da6-a31e-47cceb39c9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.1.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221122-py3-none-any.whl size=61484 sha256=40e8e5f3cf41f4d409a5dc690c0a4898af8a09c3ee79514c9ac71d0ee0395c97\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/6e/e3/602889ca9c5c55020f8d205066445ac5b1b96df59f75170ca0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=18e4f656fe519c83dffd9d3edf526944eb127ae6a8dbef76bf4f9da8016b48b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221122 iopath-0.1.10 portalocker-2.6.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/pytorch3d-0.7.1-cp38-cp38-linux_x86_64.whl (47.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.2 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221122)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.1.1)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.1.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.6.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.1\n"
          ]
        }
      ],
      "source": [
        "# install pytorch3d\n",
        "import torch, torchvision\n",
        "\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install pytorch3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwMePHahujyE",
        "outputId": "edcd31b2-712a-4117-83a6-b5d6392429a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting smplpytorch\n",
            "  Downloading smplpytorch-0.0.8-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from smplpytorch) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from smplpytorch) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from smplpytorch) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->smplpytorch) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->smplpytorch) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->smplpytorch) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->smplpytorch) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->smplpytorch) (1.15.0)\n",
            "Installing collected packages: smplpytorch\n",
            "Successfully installed smplpytorch-0.0.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.8/dist-packages (from chumpy) (1.7.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from chumpy) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy>=0.13.0->chumpy) (1.21.6)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58286 sha256=143f39d1f3690d47d134c5aae8ce9172316cd2569ab7e941b1761017051c0a22\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a2/b8/b8aeeeaeb01b5002085156add1aed832f2fb03e79d0f22dfed\n",
            "Successfully built chumpy\n",
            "Installing collected packages: chumpy\n",
            "Successfully installed chumpy-0.70\n"
          ]
        }
      ],
      "source": [
        "# install SMPL dependencies\n",
        "!pip install smplpytorch\n",
        "!pip install chumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_SmI6JiO_wN",
        "outputId": "7f51bdf8-4f4a-47ba-f396-fb376fdfc9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.5)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-k_48g6tz\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-k_48g6tz\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (4.64.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (0.13.1+cu113)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->clip==1.0) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369408 sha256=1c3d8939e1a0cacd90f111de7e3abaa91b89b4a2009e3a66a9d25bfcbe7c34bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-htb9qu3s/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwp9Ul6WuTGh"
      },
      "source": [
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUwF2IHEJuyg",
        "outputId": "e9e531d7-abac-46cf-89b5-0caf2223c333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frq2ONHFKtpQ",
        "outputId": "adcc8db6-1cf1-4272-972d-9f3595d5ad7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lg_--eluTGh",
        "outputId": "0ba68c81-4336-45f1-f54d-a55a4cf1fb57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# GPU or CPU\n",
        "gpu, cpu = None, None\n",
        "if torch.cuda.is_available():\n",
        "    gpu = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(gpu)\n",
        "else:\n",
        "    cpu = torch.device(\"cpu\")\n",
        "dev = gpu if gpu is not None else cpu\n",
        "dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVPYSGzraGX_"
      },
      "source": [
        "### Local Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svLlbat9aLZy",
        "outputId": "7bfadad1-52ef-4cbc-d90f-d4ec9b968323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/smplpytorch/pytorch/smpl_layer.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)\n",
            "  torch.Tensor(smpl_data['betas'].r).unsqueeze(0))\n"
          ]
        }
      ],
      "source": [
        "from project.smpl import SMPLwrapper, mesh_from\n",
        "from project.textures import TexturesFactory\n",
        "from project.rendering import CamerasFactory, Renderer\n",
        "from project.clipmodel import CLIPmodel\n",
        "\n",
        "import clip\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBh32HzDuTGi"
      },
      "source": [
        "### SMPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l5IDdOc9uTGk"
      },
      "outputs": [],
      "source": [
        "# initalize a textures factory\n",
        "txfactory = TexturesFactory(device=dev)\n",
        "# use the texture factory to create a texture generator: a function that takes faces and creates a texture\n",
        "def texture_generator(faces):\n",
        "  nfaces = len(faces[0])\n",
        "  texture = txfactory.from_facecolor(nfaces=nfaces, facecolor=(0.5, 0.5, 0.5))\n",
        "  return texture\n",
        "# pose and shape initalization\n",
        "pose_vect = torch.zeros(1, 72, requires_grad=True, device=dev) # theta\n",
        "shape_vect = torch.zeros(1, 10, requires_grad=True, device=dev) # beta\n",
        "# create the smpl model\n",
        "smpl_model = SMPLwrapper(model=None, txmapping=texture_generator, device=dev) #model=None uses the default model\n",
        "# create the mesh\n",
        "mesh = smpl_model.mesh(theta=pose_vect, beta=shape_vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et2fXSyz9mCU"
      },
      "source": [
        "### Differentiable Renderer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WdHsi04huTGk"
      },
      "outputs": [],
      "source": [
        "# create a cameras factory\n",
        "camsfactory = CamerasFactory(device=dev)\n",
        "# create a camera using the cameras factory\n",
        "camera = camsfactory.fov_persp_scs(coords=(2.25, 0, 0), fov=60, frustrum_depth=(1, 100))\n",
        "# create a renderer\n",
        "renderer = Renderer(device=dev, cameras=camera)\n",
        "# render the textured mesh generated by SMPL\n",
        "image = renderer.render(mesh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "v1AvDs_ZmBYw",
        "outputId": "0eb92fe1-22ab-44e6-e105-c0239b53a9fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# a quick visualization of the rendered mesh\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image[0, ..., :3].detach().cpu().numpy())\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLIP"
      ],
      "metadata": {
        "id": "lRr5J5dBxbN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVrlxkblaVN7",
        "outputId": "da2502f7-6a58-4ee3-ac6b-4d3452436781"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLIP (with PIL Image input)\n",
        "\n",
        "If this one runs, the other case below will not"
      ],
      "metadata": {
        "id": "VbTYC6k_xTRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model_pil = CLIPmodel(model=\"RN50\")"
      ],
      "metadata": {
        "id": "FErEqnjqxTzy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = renderer.render(mesh)\n",
        "\n",
        "image = image.squeeze()\n",
        "image = torch.permute(image, (2, 0, 1))\n",
        "image_pil = torchvision.transforms.ToPILImage()(image)"
      ],
      "metadata": {
        "id": "UYGtzu_9yENM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"apple\"\n",
        "cosine_distance = clip_model_pil.get_cosine_difference(image_pil, prompt)\n",
        "cosine_distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQ7PH0yxt8k",
        "outputId": "1533c628-7667-4426-9eeb-194088be084e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8341417759656906"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"human\"\n",
        "cosine_distance = clip_model_pil.get_cosine_difference(image_pil, prompt)\n",
        "cosine_distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TnClN5Axup5",
        "outputId": "1994680d-1e61-4803-abd5-441559aa28d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8244954198598862"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIITHUDZ9qgF"
      },
      "source": [
        "### CLIP (without PIL Image input, handles Image tensors directly)\n",
        "\n",
        "If this one runs, the other case above will not"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model_nopil = CLIPmodel(model=\"RN50\")"
      ],
      "metadata": {
        "id": "NH1WsPHJTt0x"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = renderer.render(mesh)\n",
        "\n",
        "image = image.squeeze()\n",
        "image = torch.permute(image, (2, 0, 1))\n",
        "image = image[:3,:,:]"
      ],
      "metadata": {
        "id": "8_dCyX96xaUD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7n8od5cMIwG",
        "outputId": "c252f2c3-74d4-4362-da42-8235f17f2916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/project/clipmodel.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8286291360855103"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "prompt = \"apple\"\n",
        "cosine_distance = clip_model_nopil.get_cosine_difference(image, prompt)\n",
        "cosine_distance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"human\"\n",
        "cosine_distance = clip_model_nopil.get_cosine_difference(image, prompt)\n",
        "cosine_distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k7r8tfewYw-",
        "outputId": "a90fbef6-728e-4fbb-8015-59dd35ab1b77"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8218399882316589"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Backpropagation"
      ],
      "metadata": {
        "id": "ixaElznmxBFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from project.optimization import OptimEnv\n",
        "from project.model import build_model\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "srwiWazpw_EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765a54fd-8e60-4bf9-d1a4-c57c46766f0c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model = CLIPmodel(model=\"RN50\")\n",
        "clip_model.eval()\n",
        "model = build_model(smpl=smpl_model, renderer=renderer, clip_model=clip_model)"
      ],
      "metadata": {
        "id": "YSfWeu2M0yXG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimenv = OptimEnv(model=model, params=[pose_vect])\n",
        "opti_pose, opti_shape = optimenv.optimize(\n",
        "    pose=pose_vect, shape=shape_vect, prompt=\"human standing up\", n_passes=1000)\n",
        "print(\"optimal pose:\\n\",opti_pose,\"\\noptimal shape:\\n\",opti_shape)"
      ],
      "metadata": {
        "id": "QRpoR0qe1A1E",
        "outputId": "e3499c77-0c82-4c7c-ba7f-bd1741bbf302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/project/clipmodel.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prep_images_tensor = torch.tensor(self.preprocess(image)).cuda().unsqueeze(0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-63379d3ec552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimenv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpose_vect\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopti_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpose_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human standing up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimal pose:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopti_pose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\noptimal shape:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopti_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/project/optimization.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, pose, shape, prompt, n_passes, verbose)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/project/optimization.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iwp9Ul6WuTGh"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}